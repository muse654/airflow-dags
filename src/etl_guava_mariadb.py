import pandas as pd
from etl_base import ETLBase
from db_connectors import DatabaseConnector
import logging

logger = logging.getLogger(__name__)


class GuavaMariaDBETL(ETLBase):
    """Guava MariaDBì—ì„œ Target ClickHouseë¡œ ë°ì´í„° ì´ê´€ (PK ê¸°ì¤€ ì¤‘ë³µ ì œê±°)"""
    
    def __init__(self, table_name, query=None, primary_key=None):
        super().__init__(f"Guava_MariaDB_{table_name}")
        self.table_name = table_name
        self.base_query = query or f"SELECT * FROM {table_name}"
        
        # primary_key ì²˜ë¦¬ ìˆ˜ì •
        if primary_key is None:
            self.primary_key = None
        elif isinstance(primary_key, str):
            self.primary_key = [primary_key]  # ë¬¸ìì—´ â†’ ë¦¬ìŠ¤íŠ¸
        elif isinstance(primary_key, (list, tuple)):
            self.primary_key = list(primary_key)  # ë¦¬ìŠ¤íŠ¸/íŠœí”Œ â†’ ë¦¬ìŠ¤íŠ¸
        else:
            self.primary_key = [str(primary_key)]  # ê¸°íƒ€ â†’ ë¬¸ìì—´ ë³€í™˜ í›„ ë¦¬ìŠ¤íŠ¸
        
        self.source_conn = None
        self.target_client = None
        
    def extract(self):
        """MariaDBì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            self.source_conn = DatabaseConnector.get_mariadb_connection('GUAVA')
            self.target_client = DatabaseConnector.get_clickhouse_client('TARGET')
            
            logger.info(f"ì „ì²´ ë°ì´í„° ì¶”ì¶œ (PK '{self.primary_key}' ê¸°ì¤€ ì¤‘ë³µ ìë™ ì œê±°)")
            
            df = pd.read_sql(self.base_query, self.source_conn)
            logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {len(df):,}ê±´")
            return df
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def transform(self, data):
        """ë°ì´í„° ë³€í™˜"""
        if len(data) == 0:
            return data
        
        # í—¤ë” í–‰ ì œê±°
        first_col = data.columns[0]
        data = data[data[first_col] != first_col]
        
        if len(data) == 0:
            logger.warning("í—¤ë” í–‰ ì œê±° í›„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return data
        
        # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜
        data.columns = [col.lower() for col in data.columns]
        
        # NULL ê°’ ì²˜ë¦¬
        for col in data.columns:
            if data[col].dtype == 'object':
                data[col] = data[col].fillna('')
            elif data[col].dtype in ['int64', 'int32', 'float64', 'float32']:
                data[col] = data[col].fillna(0)
            elif data[col].dtype == 'datetime64[ns]':
                data[col] = data[col].apply(
                    lambda x: x.strftime('%Y-%m-%d %H:%M:%S') if pd.notna(x) else None
                )
                logger.debug(f"DateTime ì»¬ëŸ¼ '{col}' â†’ String ë³€í™˜")
        
        # ì‹œìŠ¤í…œ ì¶œì²˜ ì»¬ëŸ¼ ì¶”ê°€
        data['source_system'] = 'guava'
        data['source_table'] = self.table_name
        
        logger.info(f"ë³€í™˜ ì™„ë£Œ: {len(data):,}ê±´")
        
        return data
    
    def load(self, data):
        """ClickHouseì— ë°ì´í„° ì ì¬ (PK ê¸°ì¤€ ì¤‘ë³µ ì œê±°)"""
        if len(data) == 0:
            logger.info("ì ì¬í•  ë°ì´í„° ì—†ìŒ")
            return
            
        try:
            if not self.target_client:
                self.target_client = DatabaseConnector.get_clickhouse_client('TARGET')
                
            target_table = f"guava_{self.table_name}"
            
            result = self.target_client.query(f"EXISTS TABLE `{target_table}`")
            table_exists = result.result_rows[0][0]
            
            if not table_exists:
                self._create_table_if_not_exists(target_table, data)
            
            logger.info(f"ì‚½ì…í•  ë°ì´í„°: {len(data):,}ê±´")
            
            column_names = list(data.columns)
            data_list = data.values.tolist()
            
            self.target_client.insert(
                table=target_table,
                data=data_list,
                column_names=column_names
            )
            
            logger.info(f"âœ… {len(data):,}ê±´ ì‚½ì… ì™„ë£Œ")
            
            logger.info(f"ğŸ”„ ì¤‘ë³µ ì œê±° ì‹œì‘ (PK: {self.primary_key})...")
            self.target_client.command(f"OPTIMIZE TABLE `{target_table}` FINAL")
            logger.info(f"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ")
            
            verify_result = self.target_client.query(f"SELECT count() FROM `{target_table}`")
            total_count = verify_result.result_rows[0][0]
            logger.info(f"ğŸ“Š ìµœì¢… í…Œì´ë¸” ê±´ìˆ˜: {total_count:,}ê±´")
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _create_table_if_not_exists(self, table_name, df):
        """ClickHouse í…Œì´ë¸” ìë™ ìƒì„± (ë³µí•© PK ì§€ì›)"""
        type_mapping = {
            'int64': 'Int64',
            'int32': 'Int32',
            'uint64': 'UInt64',
            'uint32': 'UInt32',
            'float64': 'Float64',
            'float32': 'Float32',
            'object': 'String',
            'datetime64[ns]': 'String',
            'bool': 'UInt8'
        }
        
        columns = []
        
        if self.primary_key:
            missing_keys = [pk for pk in self.primary_key if pk not in df.columns]
            if missing_keys:
                logger.warning(f"ì§€ì •ëœ PK {missing_keys}ê°€ ë°ì´í„°ì— ì—†ìŒ, ìë™ ê°ì§€")
                self.primary_key = None
        
        if not self.primary_key:
            detected_pks = [col for col in df.columns if col.endswith('_id')]
            if detected_pks:
                self.primary_key = detected_pks
            else:
                self.primary_key = [df.columns[0]]
        
        pk_str = ', '.join(self.primary_key)
        logger.info(f"Primary Key: {pk_str}")
        
        # ì»¬ëŸ¼ ì •ì˜
        for col_name, dtype in df.dtypes.items():
            dtype_str = str(dtype)
            ch_type = type_mapping.get(dtype_str, 'String')
            
            # ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ í™•ì¸
            if col_name in self.primary_key or col_name in ['source_system', 'source_table']:
                columns.append(f"`{col_name}` {ch_type}")
            else:
                columns.append(f"`{col_name}` Nullable({ch_type})")
        
        order_by_clause = ', '.join([f"`{pk}`" for pk in self.primary_key])
        
        create_table_sql = f"""
        CREATE TABLE `{table_name}` (
            {', '.join(columns)}
        ) ENGINE = ReplacingMergeTree()
        ORDER BY ({order_by_clause})
        """
        
        logger.info(f"í…Œì´ë¸” ìƒì„± SQL:\n{create_table_sql}")
        
        self.target_client.command(create_table_sql)
        logger.info(f"âœ… í…Œì´ë¸” `{table_name}` ìƒì„± ì™„ë£Œ")
    
    def __del__(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.source_conn:
            self.source_conn.close()
        if self.target_client:
            self.target_client.close()